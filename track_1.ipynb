{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track 1\n",
    "**Discrete Text Representation**: Choose a discrete representation method we have seen in class, such as n-gram word or character-level representations, Count Vectorizer, or TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install these versions of the libraries in case of conflicts between them\n",
    "# Terminal\n",
    "# pip install pandas==2.2.3 numpy==1.26.4 scikit-learn==1.6.1 nltk==3.9.1\n",
    "# Jupyter Notebook\n",
    "# %pip install pandas==2.2.3 numpy==1.26.4 scikit-learn==1.6.1 nltk==3.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU on Test Split: 0.08988348156035171\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import re\n",
    "import string\n",
    "\n",
    "# 1. Loading Data\n",
    "train_prompts = pd.read_csv(\"train_prompts.csv\")\n",
    "train_responses = pd.read_csv(\"train_responses.csv\")\n",
    "dev_prompts = pd.read_csv(\"dev_prompts.csv\")\n",
    "dev_responses = pd.read_csv(\"dev_responses.csv\")\n",
    "\n",
    "# 2. Combine datasets and split 80% train and 20% test\n",
    "combined_prompts = pd.concat([train_prompts, dev_prompts], ignore_index=True)\n",
    "combined_responses = pd.concat([train_responses, dev_responses], ignore_index=True)\n",
    "train_prompts, test_prompts, train_responses, test_responses = train_test_split(\n",
    "    combined_prompts, combined_responses, test_size=0.2, random_state=100\n",
    ")\n",
    "\n",
    "# 3. Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation while keeping apostrophes, hyphens, some meaningful characters\n",
    "    text = re.sub(r'[^\\w\\s\\'-?!.:@]', '', text)\n",
    "    \n",
    "    # Normalize spaces and handle multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "train_prompts[\"user_prompt\"] = train_prompts[\"user_prompt\"].apply(preprocess_text)\n",
    "test_prompts[\"user_prompt\"] = test_prompts[\"user_prompt\"].apply(preprocess_text)\n",
    "\n",
    "# 4. TF-IDF and Retrieving\n",
    "# No stop word removal to preserve all potential meaningful tokens\n",
    "# Using unigrams only for simplicity\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=None,  \n",
    "    ngram_range=(1, 1),  \n",
    ")\n",
    "tfidf_matrix = vectorizer.fit_transform(train_prompts[\"user_prompt\"])\n",
    "test_tfidf = vectorizer.transform(test_prompts[\"user_prompt\"])\n",
    "\n",
    "similarities = cosine_similarity(test_tfidf, tfidf_matrix)\n",
    "retrieved_indices = np.argmax(similarities, axis=1)\n",
    "retrieved_responses = train_responses.iloc[retrieved_indices][\"model_response\"].values\n",
    "\n",
    "# 5. Compute BLEU Score on Test Split\n",
    "test_split = test_prompts.copy()\n",
    "test_split[\"retrieved_response\"] = retrieved_responses\n",
    "test_split[\"model_response\"] = test_responses[\"model_response\"].astype(str)\n",
    "test_split[\"retrieved_response\"] = test_split[\"retrieved_response\"].astype(str)\n",
    "\n",
    "smoothingfunction = SmoothingFunction()\n",
    "test_split[\"bleu_score\"] = test_split.apply(\n",
    "    lambda x: sentence_bleu(\n",
    "        [x[\"model_response\"].split()],\n",
    "        x[\"retrieved_response\"].split(),\n",
    "        weights=(0.5, 0.5, 0, 0),\n",
    "        smoothing_function=smoothingfunction.method3\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Average BLEU on Test Split:\", test_split[\"bleu_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the track_1_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission CSV created successfully:\n",
      "                    conversation_id                       response_id\n",
      "0  0cf125095fa74e129f9b7b6054d2993e  084ff7f8d7b64fa39032743aae1b64d2\n",
      "1  e6296e2a7a554a3db3152704d065498e  65df79369c95468fbf53a7a9064c9a76\n",
      "2  ee22ccf57c064f5f955f1fd2f9ed5e90  556ad1d8aff84d268c267dfc4d076de0\n",
      "3  f5ef6be6d11746e39ec404496c307ab8  66bb4159f47c48ebabcd028de3b944a7\n",
      "4  1fcea667861046d1834b17e7851dcca4  cad50072d7874e66b7cc223ba1f91fd8\n",
      "Total rows: 5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# 1. Loading Data\n",
    "train_prompts = pd.read_csv(\"train_prompts.csv\")\n",
    "train_responses = pd.read_csv(\"train_responses.csv\")\n",
    "dev_prompts = pd.read_csv(\"dev_prompts.csv\")\n",
    "dev_responses = pd.read_csv(\"dev_responses.csv\")\n",
    "test_prompts = pd.read_csv(\"test_prompts.csv\")\n",
    "\n",
    "# Remove duplicates if they exist\n",
    "train_prompts = train_prompts.drop_duplicates(subset=['conversation_id'])\n",
    "dev_prompts = dev_prompts.drop_duplicates(subset=['conversation_id'])\n",
    "test_prompts = test_prompts.drop_duplicates(subset=['conversation_id'])\n",
    "\n",
    "# 2. Combine TRAIN and DEV datasets for training\n",
    "combined_prompts = pd.concat([train_prompts, dev_prompts], ignore_index=True)\n",
    "combined_responses = pd.concat([train_responses, dev_responses], ignore_index=True)\n",
    "\n",
    "# 3. Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation while keeping apostrophes, hyphens, some meaningful characters\n",
    "    text = re.sub(r'[^\\w\\s\\'-?!.:@]', '', text)\n",
    "    \n",
    "    # Normalize spaces and handle multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "combined_prompts[\"user_prompt\"] = combined_prompts[\"user_prompt\"].apply(preprocess_text)\n",
    "test_prompts[\"user_prompt\"] = test_prompts[\"user_prompt\"].apply(preprocess_text)\n",
    "\n",
    "# 4. TF-IDF and Retrieving\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=None,  # No stop word removal\n",
    "    ngram_range=(1, 1),  # Unigrams only\n",
    ")\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_prompts[\"user_prompt\"])\n",
    "test_tfidf = vectorizer.transform(test_prompts[\"user_prompt\"])\n",
    "\n",
    "# Compute similarities and find most similar prompts\n",
    "similarities = cosine_similarity(test_tfidf, tfidf_matrix)\n",
    "retrieved_indices = np.argmax(similarities, axis=1)\n",
    "\n",
    "# 5. Create submission CSV\n",
    "submission = pd.DataFrame({\n",
    "    'conversation_id': test_prompts['conversation_id'].reset_index(drop=True),\n",
    "    'response_id': combined_prompts.iloc[retrieved_indices]['conversation_id'].reset_index(drop=True)\n",
    "})\n",
    "\n",
    "# Save submission CSV\n",
    "submission.to_csv('track_1_test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
